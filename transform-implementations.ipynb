{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":221330082,"sourceType":"kernelVersion"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config IPCompleter.greedy = True\n%config Completer.use_jedi = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:16:12.831206Z","iopub.execute_input":"2025-03-05T15:16:12.831418Z","iopub.status.idle":"2025-03-05T15:16:12.840373Z","shell.execute_reply.started":"2025-03-05T15:16:12.831396Z","shell.execute_reply":"2025-03-05T15:16:12.839555Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np # linear algebra\nfrom numpy.lib.stride_tricks import sliding_window_view\nimport cupy as cp\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport timeseriesanalysis as tsa\n!pip install bezier\n!pip install lmoments3\nimport lmoments3 as lm\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom numba import njit\nimport itertools \nfrom scipy.special import comb\nfrom scipy import signal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:16:51.090481Z","iopub.execute_input":"2025-03-05T15:16:51.090835Z","iopub.status.idle":"2025-03-05T15:16:59.186408Z","shell.execute_reply.started":"2025-03-05T15:16:51.090808Z","shell.execute_reply":"2025-03-05T15:16:59.185653Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bezier in /usr/local/lib/python3.10/dist-packages (2024.6.20)\nRequirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from bezier) (2.2.3)\nCollecting lmoments3\n  Using cached lmoments3-1.0.8-py3-none-any.whl.metadata (46 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lmoments3) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lmoments3) (1.13.1)\nUsing cached lmoments3-1.0.8-py3-none-any.whl (48 kB)\nInstalling collected packages: lmoments3\nSuccessfully installed lmoments3-1.0.8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Kernel Function Computations For GPUs**","metadata":{}},{"cell_type":"code","source":"def remove_duplicate_arrays(array_list):\n    \"\"\"\n    Removes duplicate NumPy arrays from a list, returning a new list\n    containing only unique arrays.\n\n    Args:\n        array_list (list of numpy arrays): A list containing NumPy arrays.\n\n    Returns:\n        list of numpy arrays: A new list containing only the unique NumPy arrays\n                              from the input list. The order of arrays in the\n                              returned list is preserved from the original list\n                              as much as possible (the *first* occurrence of each\n                              unique array is kept).\n    \"\"\"\n\n    unique_arrays = []\n    seen = set()  # Use a set to track seen array's byte representations\n\n    for arr in array_list:\n        # Convert the array to bytes for efficient set comparison\n        arr_bytes = arr.tobytes()\n\n        if arr_bytes not in seen:\n            unique_arrays.append(arr)\n            seen.add(arr_bytes)\n\n    return unique_arrays\n    \n\ndef bezier_curve_fast_cupy(control_points, num_points=100):\n    \"\"\"\n    Generates 2D Bézier curves for a batch of control point arrangements,\n    optimized for speed using CuPy, and scales each curve so that its points sum to 1.\n\n    Args:\n        control_points (cupy array): A CuPy array of shape (num_arrangements, n+1, 2)\n            representing the control points for each Bézier curve.\n        num_points (int): The number of points to generate along each curve.\n\n    Returns:\n        cupy array: A CuPy array of shape (num_arrangements, num_points, 2) containing the (x, y)\n            coordinates of the points on the Bézier curves, scaled to sum to 1.\n    \"\"\"\n\n    n = control_points.shape[1] - 1\n    num_arrangements = control_points.shape[0]\n\n    # Precompute Bernstein basis polynomials for all t values\n    t = cp.linspace(0, 1, num_points)[:, None]\n\n    # Precompute the binomial coefficients (on the CPU, then transfer)\n    binomial_coefficients = np.array([comb(n, i) for i in range(n + 1)])\n    binomial_coefficients_gpu = cp.asarray(binomial_coefficients)\n\n    # Vectorized calculation of Bernstein polynomials\n    bernstein_polynomials = binomial_coefficients_gpu * (t ** cp.arange(n + 1).reshape(1, -1)) * ((1 - t) ** cp.arange(n, -1, -1).reshape(1, -1))\n\n    # Calculate curve points using vectorized operations (Batch Matrix Multiplication)\n    points = cp.matmul(bernstein_polynomials, control_points)\n\n    # Scale the curve to sum to 1\n    curve_sum = cp.sum(points, axis=1, keepdims=True)\n    mask = (curve_sum != 0)\n    points = cp.where(mask, points / curve_sum, points)\n\n    return points.astype(cp.float16)\n\n\n\ndef generate_coordinate_arrangements_cupy(point_ranges):\n    \"\"\"\n    Generates all possible coordinate arrangements for a specified number of points,\n    where each point can have its own independent x and y ranges.\n\n    Args:\n        point_ranges (list of tuples): A list of tuples, where each tuple represents the\n            (x_range, y_range) for a single point.  Each x_range and y_range are themselves\n            tuples specifying (min_x, max_x) and (min_y, max_y), respectively.\n\n            For example:\n            `point_ranges = [((0, 2), (0, 3)), ((1, 4), (2, 5)), ((0, 1), (1, 1))]`\n            means:\n                - Point 1: x can be 0, 1, or 2; y can be 0, 1, 2, or 3.\n                - Point 2: x can be 1, 2, 3, or 4; y can be 2, 3, 4, or 5.\n                - Point 3: x can be 0 or 1; y can only be 1.\n\n    Returns:\n        A CuPy array of shape (num_arrangements, num_points, 2).\n    \"\"\"\n    arrangements = []\n    num_points = len(point_ranges)\n\n    def generate_recursive(current_arrangement, point_index):\n        if point_index == num_points:\n            arrangements.append(np.array(current_arrangement))\n            return\n\n        x_range, y_range = point_ranges[point_index]\n        for x in range(x_range[0], x_range[1] + 1):\n            for y in range(y_range[0], y_range[1] + 1):\n                new_arrangement = current_arrangement + [[x, y]]\n                generate_recursive(new_arrangement, point_index + 1)\n\n    generate_recursive([], 0)\n    return cp.asarray(arrangements)\n\n\n# Example Usage:\n# Define the individual x and y ranges for each point\n\nmin_x = 0\nmax_x = 4\nmin_y = 0\nmax_y = 7\n\npoint_ranges = [\n    ((min_x, min_x), (min_y, max_y)),\n    ((min_x, max_x), (min_y, max_y)),\n    ((min_x, max_x), (min_y, max_y)),\n    ((max_x, max_x), (min_y, max_y))  \n]\n\n# Generate all arrangements\nall_arrangements_gpu = generate_coordinate_arrangements_cupy(point_ranges)\n\nmin_window_size = 10\nmax_window_size = 1000\nwindow_size_step = 15\nloop_points = range(min_window_size, max_window_size, window_size_step)\nenum_loop_points = enumerate(loop_points)\n\n# Preallocate the array to store the kernel functions (on the CPU)\nkernel_functions = [] # Changed from np.empty to a list\n\nwith tqdm(desc=\"Processing\") as pbar:\n    for window_index, window_size in enum_loop_points:\n        # Calculate all Bezier curves for the current window size in one go!\n        all_curves = bezier_curve_fast_cupy(all_arrangements_gpu, num_points=window_size) #shape is num_arrangements, num_points, 2\n        y_coords_gpu = all_curves[:, :, 1]  # Extract y-coordinates; shape is num_arrangements, num_points\n\n        # Copy y-coordinates to CPU as a NumPy array\n        y_coords_cpu = cp.asnumpy(y_coords_gpu)  #Shape is now num_arrangements, num_points\n\n        #Store NumPy Array as a 2D array in the list.\n        kernel_functions.append(y_coords_cpu) #Changed to append, not assign\n\n        pbar.update(1)\n\n# leave unique kernel functions only\nfor i in range(len(kernel_functions)):\n    kernel_functions[i] = remove_duplicate_arrays(kernel_functions[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T14:03:48.989666Z","iopub.execute_input":"2025-03-05T14:03:48.990706Z","iopub.status.idle":"2025-03-05T14:04:07.335479Z","shell.execute_reply.started":"2025-03-05T14:03:48.990671Z","shell.execute_reply":"2025-03-05T14:04:07.334583Z"}},"outputs":[{"name":"stderr","text":"Processing: 66it [00:11,  5.72it/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **Kernel Function Computations For TPUs**","metadata":{}},{"cell_type":"code","source":"tfd = tfp.distributions\n\ndef bezier_curve_fast_tf(control_points, num_points=100):\n    \"\"\"\n    Generates 2D Bézier curves for a batch of control point arrangements,\n    optimized for speed using TensorFlow and TPUs, and scales each curve so that its points sum to 1.\n\n    Args:\n        control_points (tf.Tensor): A TensorFlow tensor of shape (num_arrangements, n+1, 2)\n            representing the control points for each Bézier curve.\n        num_points (int): The number of points to generate along each curve.\n\n    Returns:\n        tf.Tensor: A TensorFlow tensor of shape (num_arrangements, num_points, 2) containing the (x, y)\n            coordinates of the points on the Bézier curves, scaled to sum to 1.\n    \"\"\"\n\n    n = tf.cast(tf.shape(control_points)[1] - 1, dtype=tf.float32)  # Use tf.cast\n    num_arrangements = tf.shape(control_points)[0]\n\n    # Precompute Bernstein basis polynomials for all t values\n    t = tf.linspace(0.0, 1.0, num_points)[:, None]\n\n    # Precompute the binomial coefficients (on the CPU, then transfer if needed - usually XLA handles this fine)\n    binomial_coefficients = np.array([comb(int(n), i) for i in range(int(n) + 1)])\n    binomial_coefficients_tf = tf.constant(binomial_coefficients, dtype=tf.float32) # Convert to tf.constant\n\n    # Vectorized calculation of Bernstein polynomials\n    arange_n_plus_1 = tf.range(int(n + 1), dtype=tf.float32)\n    bernstein_polynomials = binomial_coefficients_tf * (t ** arange_n_plus_1) * ((1 - t) ** tf.reverse(arange_n_plus_1, axis=[0]))\n\n    # Calculate curve points using vectorized operations (Batch Matrix Multiplication)\n    bernstein_polynomials = tf.cast(bernstein_polynomials, dtype=tf.float32)\n    control_points = tf.cast(control_points, dtype=tf.float32)\n    points = tf.matmul(bernstein_polynomials, control_points)\n\n    # Scale the curve to sum to 1\n    curve_sum = tf.reduce_sum(points, axis=1, keepdims=True)\n    mask = tf.not_equal(curve_sum, 0)\n    points = tf.where(mask, points / curve_sum, points)\n\n    return tf.cast(points, dtype=tf.float16)\n\n\ndef generate_coordinate_arrangements_tf():\n    \"\"\"\n    Generates all possible coordinate arrangements for four points, as a TensorFlow tensor.\n\n    Returns:\n        A TensorFlow tensor of shape (num_arrangements, 4, 2).\n    \"\"\"\n    arrangements = []\n    for y1 in range(0, 7):\n        for x2 in range(0, 5):\n            for y2 in range(0, 7):\n                for x3 in range(0, 5):\n                    for y3 in range(0, 7):\n                        for y4 in range(0, 7):\n                            point1 = [0, y1]\n                            point2 = [x2, y2]\n                            point3 = [x3, y3]\n                            point4 = [4, y4]\n                            arrangements.append(np.array([point1, point2, point3, point4]))\n\n    return tf.constant(np.array(arrangements), dtype=tf.float32)\n\n\n# TPU Strategy Setup (REQUIRED if running on TPU)\n# This part needs to be adjusted based on your specific TPU setup\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default strategy in case of no TPU\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Now, wrap everything that uses the TPU inside the strategy scope\nwith strategy.scope():\n    # Generate all arrangements\n    all_arrangements_tf = generate_coordinate_arrangements_tf()\n\n    min_window_size = 10\n    max_window_size = 1000\n    window_size_step = 15\n    loop_points = range(min_window_size, max_window_size, window_size_step)\n    enum_loop_points = enumerate(loop_points)\n\n    # Preallocate the array to store the kernel functions (on the CPU)\n    kernel_functions = np.empty((len(loop_points), len(all_arrangements_tf)), dtype=object)\n\n\n    with tqdm(desc=\"Processing\") as pbar:\n        for window_index, window_size in enum_loop_points:\n            # Calculate all Bezier curves for the current window size in one go!\n            all_curves = bezier_curve_fast_tf(all_arrangements_tf, num_points=window_size) #shape is num_arrangements, num_points, 2\n            y_coords_tf = all_curves[:, :, 1]  # Extract y-coordinates; shape is num_arrangements, num_points\n\n            # Convert y_coords_tf to NumPy array\n            y_coords_np = y_coords_tf.numpy()\n\n            # Store NumPy Array in 2d output.\n            kernel_functions[window_index, :] = [y_coords_np[i, :] for i in range(y_coords_np.shape[0])]\n\n            pbar.update(1)\n\nprint(\"Finished processing.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Computations for Multiscale LTI Filter Information","metadata":{}},{"cell_type":"code","source":"def conv_subtract_scale(time_series, kernel_functions):\n    \"\"\"\n    Performs convolution, subtraction, and scaling operations efficiently, \n    minimizing data conversions.\n\n    Args:\n        time_series: A 1D NumPy array of time series data.\n        kernel_functions: A 2D NumPy array of kernel functions.\n\n    Returns:\n        A TensorFlow tensor representing the result of the operations.\n    \"\"\"\n\n    # 1. Preprocessing & Reshaping in NumPy (Optimize for TF Input)\n    time_series = np.expand_dims(time_series, axis=(0, -1))  # (1, time_series_length, 1)\n    kernel_functions = np.expand_dims(kernel_functions, axis=1)  # (num_kernel_functions, 1, kernel_length)\n    kernel_functions = np.transpose(kernel_functions, (2, 1, 0))  # (kernel_length, 1, num_kernel_functions)\n\n    # 2. Convert to TensorFlow tensors\n    time_series_tf = tf.convert_to_tensor(time_series, dtype=tf.float16)\n    kernel_functions_tf = tf.convert_to_tensor(kernel_functions, dtype=tf.float16)\n\n    # 3. Convolution in TensorFlow\n    convolved_tf = tf.nn.convolution(\n        input=time_series_tf,\n        filters=kernel_functions_tf,\n        padding='VALID',\n        strides=1,\n    )\n    convolved_tf = tf.squeeze(convolved_tf, axis=0)  # Remove batch dim\n\n    # 4. Reshape time_series_tf for subtraction (all in TensorFlow)\n    time_series_tf = tf.reshape(time_series_tf, [time_series_tf.shape[1]])  #Now remove the dims for the tf tensor\n    starting_index = int(time_series_tf.shape[0] - convolved_tf.shape[0])\n    time_series_sliced_tf = time_series_tf[starting_index:] #Slice now in TF\n\n    # 5. Reshape for subtraction (all in TensorFlow)\n    # Determine if convolved_tf needs to be reshaped based on time_series_sliced_tf's shape\n    if time_series_sliced_tf.shape[0] == convolved_tf.shape[1]:\n        time_series_reshaped_tf = tf.reshape(time_series_sliced_tf, [1, -1])\n    elif time_series_sliced_tf.shape[0] == convolved_tf.shape[0]:\n        time_series_reshaped_tf = tf.reshape(time_series_sliced_tf, [-1, 1])\n    else:\n        raise ValueError(\"Arrays are not compatible. time_series must match either the number of rows or columns of filter outputs.\")\n    \n    # 6. Perform subtraction *directly in TensorFlow* (No CuPy conversion anymore!)\n    intermediate_result = time_series_reshaped_tf - convolved_tf\n    scaled_result = intermediate_result.numpy()\n    with tqdm(desc=\"Processing\") as pbar:\n        for i in range(scaled_result.shape[1]):\n            scaled_result[:,i] /= np.std(scaled_result[:,i])\n            pbar.update(1)\n            \n    return scaled_result\n\n# Example Time Series\nlength = 5000\nsample_rate = 10\ntime_series = tsa.symmetric_random_walk(length, sample_rate)\nresid = conv_subtract_scale(time_series, kernel_functions[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T22:52:01.257479Z","iopub.execute_input":"2025-03-03T22:52:01.257836Z","iopub.status.idle":"2025-03-03T22:52:02.256288Z","shell.execute_reply.started":"2025-03-03T22:52:01.257808Z","shell.execute_reply":"2025-03-03T22:52:02.255535Z"}},"outputs":[{"name":"stderr","text":"Processing: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\nProcessing: 3746it [00:00, 4036.02it/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Computing Sliding L-Moments","metadata":{}},{"cell_type":"code","source":"def sliding_lmoments(data, window_size, orders):\n    \"\"\"\n    Compute L-moments over a sliding window of a 1D NumPy array using sliding_window_view.\n    \n    Parameters:\n    - data: 1D NumPy array, time series data\n    - window_size: int, size of the sliding window\n    - orders: int or list of ints, number of L-moments or specific orders\n    \n    Returns:\n    - 2D NumPy array: rows are windows, columns are L-moments\n    \n    Raises:\n    - ValueError: if inputs are invalid\n    \"\"\"\n    # Input validation\n    if not isinstance(data, np.ndarray) or data.ndim != 1:\n        raise ValueError(\"data must be a 1D NumPy array\")\n    if not isinstance(window_size, int) or window_size <= 0:\n        raise ValueError(\"window_size must be a positive integer\")\n    if window_size > len(data):\n        raise ValueError(\"window_size must be <= data length\")\n    \n    # Determine number of L-moments to compute\n    if isinstance(orders, int):\n        if orders <= 0:\n            raise ValueError(\"orders must be a positive integer\")\n        max_order = orders\n        idx = slice(None)  # Return all computed L-moments\n    elif isinstance(orders, list):\n        if not orders or not all(isinstance(i, int) and i > 0 for i in orders):\n            raise ValueError(\"orders must be a non-empty list of positive integers\")\n        max_order = max(orders)\n        idx = [o - 1 for o in orders]  # Indices for specific L-moments\n    else:\n        raise ValueError(\"orders must be an integer or a list of positive integers\")\n    \n    # Create sliding windows\n    windows = sliding_window_view(data, window_size)\n    n_windows = windows.shape[0]\n    \n    # Compute L-moments for each window\n    # lm.lmoments doesn't vectorize, so we use a list comprehension\n    lmoments = np.array([lm.lmom_ratios(window, max_order) for window in windows])\n    \n    # Return selected L-moments\n    return lmoments[:, idx]\n\n# Example usage\nif __name__ == \"__main__\":\n    # Sample data\n    data = tsa.symmetric_random_walk(500, 20)\n    \n    # Compute first 3 L-moments over window size 3\n    result1 = sliding_lmoments(data, window_size=50, orders=6)\n    #print(\"First 3 L-moments:\\n\", result1)\n    \n    # Compute specific L-moments (L1 and L2) over window size 3\n    result2 = sliding_lmoments(data, window_size=50, orders=[1, 2])\n    #print(\"\\nL1 and L2 only:\\n\", result2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:24:32.881848Z","iopub.execute_input":"2025-03-05T15:24:32.882211Z","iopub.status.idle":"2025-03-05T15:24:33.792159Z","shell.execute_reply.started":"2025-03-05T15:24:32.882181Z","shell.execute_reply":"2025-03-05T15:24:33.791221Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom numpy.lib.stride_tricks import sliding_window_view\nimport lmoments3 as lm\n\ndef sliding_lmoments_gpu(data, window_size, orders):\n    \"\"\"\n    Compute L-moments over sliding windows using CuPy for GPU acceleration.\n    \n    Parameters:\n    - data: 1D NumPy or CuPy array, time series data\n    - window_size: int, size of the sliding window\n    - orders: int or list of ints, number of L-moments or specific orders\n    \n    Returns:\n    - 2D NumPy array: rows are windows, columns are L-moments\n    \"\"\"\n    # Convert input to CuPy array if it’s NumPy\n    if isinstance(data, np.ndarray):\n        data = cp.asarray(data)\n    elif not isinstance(data, cp.ndarray):\n        raise ValueError(\"data must be a 1D NumPy or CuPy array\")\n    if data.ndim != 1:\n        raise ValueError(\"data must be 1D\")\n    if window_size > len(data):\n        raise ValueError(\"window_size must be <= data length\")\n    \n    # Determine L-moment orders\n    if isinstance(orders, int):\n        if orders <= 0:\n            raise ValueError(\"orders must be a positive integer\")\n        max_order = orders\n        idx = slice(None)\n    elif isinstance(orders, list):\n        if not orders or not all(isinstance(i, int) and i > 0 for i in orders):\n            raise ValueError(\"orders must be a non-empty list of positive integers\")\n        max_order = max(orders)\n        idx = [o - 1 for o in orders]\n    else:\n        raise ValueError(\"orders must be an integer or a list of positive integers\")\n    \n    # Create sliding windows on GPU\n    # CuPy doesn’t have sliding_window_view, so we use NumPy and transfer\n    windows_np = sliding_window_view(data.get(), window_size)\n    windows = cp.asarray(windows_np)  # Move to GPU\n    \n    # Compute L-moments (on CPU due to lmoments3 limitation)\n    # Transfer each window to CPU, compute, and stack results\n    lmoments = np.array([lm.lmom_ratios(cp.asnumpy(window), max_order) \n                         for window in windows])\n    \n    # Return selected L-moments as NumPy array\n    return lmoments[:, idx]\n\n# Example usage\nif __name__ == \"__main__\":\n    # Sample data\n    data = tsa.symmetric_random_walk(50000, 20)\n    \n    # Run on GPU\n    result = sliding_lmoments_gpu(data, window_size=30, orders=6)\n    print(\"L1 and L2:\\n\", result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:29:50.288411Z","iopub.execute_input":"2025-03-05T15:29:50.288753Z","iopub.status.idle":"2025-03-05T15:30:49.476126Z","shell.execute_reply.started":"2025-03-05T15:29:50.288723Z","shell.execute_reply":"2025-03-05T15:30:49.475225Z"}},"outputs":[{"name":"stdout","text":"L1 and L2:\n [[ 8.13333333e-01  5.55632184e-01  2.81990661e-01  1.89668420e-01\n  -1.05259196e-01 -6.38999395e-02]\n [ 8.73333333e-01  5.72873563e-01  2.49770695e-01  1.51475197e-01\n  -1.26181069e-01 -5.00823147e-02]\n [ 9.26666667e-01  5.95402299e-01  2.17209046e-01  1.00508672e-01\n  -1.37891109e-01 -1.84866185e-02]\n ...\n [ 1.61800000e+01  7.79310345e-01  7.49683944e-02 -8.12380016e-03\n   3.54666638e-03  2.47459849e-02]\n [ 1.61000000e+01  7.36551724e-01  7.66452648e-02  1.02401760e-02\n   1.67735233e-02  3.52556100e-02]\n [ 1.60400000e+01  6.91724138e-01  5.04201681e-02  9.82238470e-03\n   3.12071518e-02  4.68395384e-02]]\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import cProfile\nimport pstats\n\n# Profile with cProfile\nprofiler = cProfile.Profile()\nprofiler.enable()\n\nresult = sliding_lmoments_gpu(data, 30, 6)\n\nprofiler.disable()\nstats = pstats.Stats(profiler).sort_stats('cumulative')\nstats.print_stats()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T15:31:38.384028Z","iopub.execute_input":"2025-03-05T15:31:38.384491Z","iopub.status.idle":"2025-03-05T15:33:30.285776Z","shell.execute_reply.started":"2025-03-05T15:31:38.384446Z","shell.execute_reply":"2025-03-05T15:33:30.284860Z"}},"outputs":[{"name":"stderr","text":"Exception ignored When destroying _lsprof profiler:\nTraceback (most recent call last):\n  File \"<ipython-input-46-b71cffd9484e>\", line 6, in <cell line: 6>\nRuntimeError: Cannot install a profile function while another profile function is being installed\n","output_type":"stream"},{"name":"stdout","text":"         205580931 function calls in 111.815 seconds\n\n   Ordered by: cumulative time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        2    0.000    0.000  111.815   55.908 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3512(run_code)\n        2    0.000    0.000  111.815   55.907 {built-in method builtins.exec}\n        1    0.000    0.000  111.815  111.815 <ipython-input-46-b71cffd9484e>:1(<cell line: 8>)\n        1    0.008    0.008  111.815  111.815 <ipython-input-43-c914fbf742a7>:6(sliding_lmoments_gpu)\n        1    0.775    0.775  111.770  111.770 <ipython-input-43-c914fbf742a7>:49(<listcomp>)\n    49971    0.132    0.000  108.872    0.002 /usr/local/lib/python3.10/dist-packages/lmoments3/__init__.py:74(lmom_ratios)\n    49971   51.177    0.001  108.740    0.002 /usr/local/lib/python3.10/dist-packages/lmoments3/__init__.py:90(_samlmularge)\n 37778076   25.927    0.000   50.494    0.000 /usr/local/lib/python3.10/dist-packages/scipy/_lib/deprecation.py:209(inner_f)\n 37778076   17.906    0.000   17.906    0.000 /usr/local/lib/python3.10/dist-packages/scipy/special/_basic.py:2644(comb)\n 75606126    6.673    0.000    6.673    0.000 {built-in method builtins.len}\n 45473610    3.880    0.000    3.880    0.000 {method 'append' of 'list' objects}\n    49971    0.062    0.000    2.063    0.000 /usr/local/lib/python3.10/dist-packages/cupy/__init__.py:795(asnumpy)\n  7745505    2.059    0.000    2.059    0.000 {built-in method builtins.sum}\n    49972    1.780    0.000    1.995    0.000 {method 'get' of 'cupy._core.core._ndarray_base' objects}\n    49971    0.108    0.000    0.704    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2177(sum)\n    49972    0.150    0.000    0.584    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:71(_wrapreduction)\n    49972    0.375    0.000    0.375    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n    49971    0.082    0.000    0.329    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:865(sort)\n    49971    0.135    0.000    0.135    0.000 {method 'sort' of 'numpy.ndarray' objects}\n    49972    0.112    0.000    0.112    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/_internal.py:250(__init__)\n    49971    0.102    0.000    0.102    0.000 {method 'copy' of 'numpy.ndarray' objects}\n    49972    0.031    0.000    0.072    0.000 /usr/local/lib/python3.10/dist-packages/cupy/_core/syncdetect.py:36(_declare_synchronize)\n    49972    0.060    0.000    0.060    0.000 {built-in method numpy.asarray}\n    49971    0.044    0.000    0.059    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/numeric.py:1855(isscalar)\n    49972    0.047    0.000    0.047    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:72(<dictcomp>)\n    49972    0.041    0.000    0.041    0.000 /usr/local/lib/python3.10/dist-packages/cupy/_core/syncdetect.py:27(_is_allowed)\n   149915    0.034    0.000    0.034    0.000 {built-in method builtins.isinstance}\n    49972    0.030    0.000    0.030    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/_internal.py:304(data)\n        4    0.029    0.007    0.029    0.007 {built-in method numpy.array}\n    49971    0.014    0.000    0.014    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:861(_sort_dispatcher)\n    49972    0.012    0.000    0.012    0.000 {method 'items' of 'dict' objects}\n    49971    0.012    0.000    0.012    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2172(_sum_dispatcher)\n    49971    0.010    0.000    0.010    0.000 {built-in method numpy.asanyarray}\n        2    0.000    0.000    0.007    0.004 /usr/local/lib/python3.10/dist-packages/cupy/_creation/from_data.py:49(asarray)\n        2    0.007    0.004    0.007    0.004 {built-in method cupy._core.core.array}\n      142    0.001    0.000    0.001    0.000 /usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py:96(_xla_gc_callback)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:123(sliding_window_view)\n        2    0.000    0.000    0.000    0.000 /usr/lib/python3.10/codeop.py:117(__call__)\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3337(_update_code_co_name)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:38(as_strided)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2322(any)\n        2    0.000    0.000    0.000    0.000 /usr/lib/python3.10/contextlib.py:279(helper)\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n        2    0.000    0.000    0.000    0.000 /usr/lib/python3.10/contextlib.py:102(__init__)\n        2    0.000    0.000    0.000    0.000 /usr/lib/python3.10/contextlib.py:130(__enter__)\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:689(__get__)\n        4    0.000    0.000    0.000    0.000 /usr/lib/python3.10/dis.py:453(findlinestarts)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:348(iterable)\n        2    0.000    0.000    0.000    0.000 /usr/lib/python3.10/contextlib.py:139(__exit__)\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/hooks.py:103(__call__)\n        4    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py:166(extra_flags)\n        1    0.000    0.000    0.000    0.000 <ipython-input-46-b71cffd9484e>:1(<cell line: 10>)\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py:651(get)\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/utils/ipstruct.py:125(__getattr__)\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3449(compare)\n        2    0.000    0.000    0.000    0.000 {method 'replace' of 'code' objects}\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:1302(user_global_ns)\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:20(__init__)\n        2    0.000    0.000    0.000    0.000 {method 'co_lines' of 'code' objects}\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:326(<genexpr>)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:25(_maybe_view_as_subclass)\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py:118(_sliding_window_view_dispatcher)\n        2    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/IPython/core/hooks.py:168(pre_run_code_hook)\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        1    0.000    0.000    0.000    0.000 /usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:2317(_any_dispatcher)\n\n\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"<pstats.Stats at 0x7fc0cafeba00>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"def find_equal_arrays(array_list):\n    \"\"\"\n    Finds and groups NumPy arrays in a list that are equal to each other.\n\n    Args:\n        array_list (list of numpy arrays): A list containing NumPy arrays.\n\n    Returns:\n        list of lists: A list where each inner list contains the *indices* of arrays\n                       in the input `array_list` that are equal to each other.  \n                       Arrays are considered equal if all their elements are equal.\n\n                       For example, if array_list = [array1, array2, array3]\n                       and array1 and array3 are equal, the function might return:\n                       [[0, 2], [1]]  (array1 and array3 are at indices 0 and 2, array2 at 1)\n\n                       or\n                       [[1], [0, 2]]\n\n                       The order of the inner lists and the order of indices within the inner\n                       lists is not guaranteed.\n    \"\"\"\n\n    equal_groups = []\n    remaining_indices = list(range(len(array_list)))  # Indices to process\n\n    while remaining_indices:\n        first_index = remaining_indices.pop(0)  # Take the first unprocessed array\n        equal_group = [first_index]\n        first_array = array_list[first_index]\n\n        # Compare to all remaining unprocessed arrays\n        indices_to_remove = []\n        for i in remaining_indices:\n            other_array = array_list[i]\n            if np.array_equal(first_array, other_array):\n                equal_group.append(i)\n                indices_to_remove.append(i)\n\n        # Remove the matched indices from remaining_indices (in reverse order to avoid shifting issues)\n        for i in sorted(indices_to_remove, reverse=True):\n            remaining_indices.remove(i)\n\n        equal_groups.append(equal_group)\n\n    return equal_groups\n\n\n# Example Usage:\narray1 = np.array([1, 2, 3])\narray2 = np.array([4, 5, 6])\narray3 = np.array([1, 2, 3])  # Equal to array1\narray4 = np.array([7, 8, 9])\narray5 = np.array([4, 5, 6])  # Equal to array2\narray6 = np.array([1, 2, 3])  # Equal to array1 and array3\n\nmy_list = [array1, array2, array3, array4, array5, array6]\nequality_groups = find_equal_arrays(my_list)\nprint(f\"Arrays equal to each other (grouped by indices): {equality_groups}\")\n\n\narray7 = np.array([1, 1, 1])\narray8 = np.array([1, 1, 1])\narray9 = np.array([2, 2, 2])\n\nmy_list2 = [array7, array8, array9]\nequality_groups2 = find_equal_arrays(my_list2)\nprint(f\"Arrays equal to each other (grouped by indices) 2: {equality_groups2}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T15:54:38.541243Z","iopub.execute_input":"2025-03-03T15:54:38.541556Z","iopub.status.idle":"2025-03-03T15:54:38.549762Z","shell.execute_reply.started":"2025-03-03T15:54:38.541509Z","shell.execute_reply":"2025-03-03T15:54:38.548931Z"}},"outputs":[{"name":"stdout","text":"Arrays equal to each other (grouped by indices): [[0, 2, 5], [1, 4], [3]]\nArrays equal to each other (grouped by indices) 2: [[0, 1], [2]]\n","output_type":"stream"}],"execution_count":2}]}